{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b23b7367-0f34-46d7-9f11-bde5542085ee",
   "metadata": {},
   "source": [
    "# Entity Extraction - 2020 file was saved as 2021 by mistake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3305d02-cd1a-45a2-9056-67a5f7396996",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b94c9b60-d8c7-4605-9e40-7f21063ea690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import re\n",
    "import sys\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0751f4e7-58f4-440d-9231-4c807df3e1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 03:26:47.010868: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-22 03:27:01.610556: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-05-22 03:27:01.613809: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-05-22 03:27:01.613834: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-05-22 03:27:08.011747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-05-22 03:27:08.035472: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-05-22 03:27:08.035570: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (nlp-final-project-notebook): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7f3d1d6c0d50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Using Spacy Large\n",
    "# !python -m spacy download en_core_web_lg\n",
    "nlp = spacy.load(\"en_core_web_lg\", disable=[\"tagger\", \"parser\"])\n",
    "\n",
    "# Enable only NER\n",
    "nlp.enable_pipe(\"ner\")\n",
    "nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01b6d2d0-a258-4a4c-98eb-b7eb56704ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk as nltk\n",
    "import nltk.corpus  \n",
    "from nltk.text import Text\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6aa99c9-07be-4cd2-96a5-aef05889b7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# Graphics in SVG format are more sharp and legible\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f82a944-2606-4664-ba5f-75b96072413f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CPUs: 16\n",
      "INFO: Pandarallel will run on 15 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "#pip install pandarallel\n",
    "import multiprocessing\n",
    "\n",
    "num_processors = multiprocessing.cpu_count()\n",
    "print(f'Available CPUs: {num_processors}')\n",
    "\n",
    "import pandarallel\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(nb_workers=num_processors-1, use_memory_fs=False, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a4777e0-4cb3-4c4d-bffa-97304fc90234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket nlp_final_project_kshitijm connected.\n"
     ]
    }
   ],
   "source": [
    "# Imports the Google Cloud client library\n",
    "from google.cloud import storage\n",
    "# Instantiates a client\n",
    "storage_client = storage.Client()\n",
    "\n",
    "# The name for the new bucket\n",
    "bucket_name = \"nlp_final_project_kshitijm\"\n",
    "\n",
    "# Creates the new bucket\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "print(f\"Bucket {bucket.name} connected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de71ef34-0253-4fdb-abf1-e400d54c162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bcef9f3-d1a2-4b88-b1b9-60785b08d2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_ner(x):\n",
    "  doc = nlp(x)\n",
    "  entities = []\n",
    "  labels = []\n",
    "  for ent in doc.ents:\n",
    "    entities.append(ent.text)\n",
    "    labels.append(ent.label_)\n",
    "  entities_labels = list(zip(entities, labels)) #we do not want unique entities\n",
    "  return entities_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94726e22-8d0c-40b3-b16d-d6cadc4bf527",
   "metadata": {},
   "source": [
    "**2020**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c6f4478-6b47-4093-96a6-d82b3e5b50f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19 s, sys: 2.51 s, total: 21.5 s\n",
      "Wall time: 1min 1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>language</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>article_source</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>title_tokens</th>\n",
       "      <th>...</th>\n",
       "      <th>year_pub</th>\n",
       "      <th>month</th>\n",
       "      <th>month-year</th>\n",
       "      <th>flag_relevant</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>rake_phrases_articles</th>\n",
       "      <th>rake_phrases_joined</th>\n",
       "      <th>final_topic</th>\n",
       "      <th>sent_probs</th>\n",
       "      <th>sent_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://fusionscienceacademy.com/artificial-in...</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>en</td>\n",
       "      <td>Artificial Intelligence (AI) in Social Media  ...</td>\n",
       "      <td>\\n\\nArtificial Intelligence (AI) in Social Med...</td>\n",
       "      <td>Artificial Intelligence AI in Social MediaMar...</td>\n",
       "      <td>2026 – Fusion Science Academy</td>\n",
       "      <td>Artificial Intelligence (AI) in Social Media  ...</td>\n",
       "      <td>['artificial', 'intelligence', 'ai', 'social',...</td>\n",
       "      <td>...</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan 2020</td>\n",
       "      <td>1</td>\n",
       "      <td>22283</td>\n",
       "      <td>['burkert fluid control systems emerson electr...</td>\n",
       "      <td>burkert fluid control systems emerson electric...</td>\n",
       "      <td>6</td>\n",
       "      <td>[[2.1574432e-04 9.9863547e-01 1.1488239e-03]]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://health.economictimes.indiatimes.com/ne...</td>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>en</td>\n",
       "      <td>artificial intelligence: Researchers develop A...</td>\n",
       "      <td>\\n\\nartificial intelligence: Researchers devel...</td>\n",
       "      <td>artificial intelligence: Researchers develop ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>artificial intelligence: Researchers develop A...</td>\n",
       "      <td>['artificial', 'intelligence', 'researchers', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan 2020</td>\n",
       "      <td>1</td>\n",
       "      <td>8087</td>\n",
       "      <td>['economic times ethealthworldhome news hospit...</td>\n",
       "      <td>economic times ethealthworldhome news hospital...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[1.9508268e-04 8.0524624e-04 9.9899966e-01]]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://heraldpublicist.com/bet-gil-on-ai-fina...</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>en</td>\n",
       "      <td>Bet Gil on AI Final Fantasy Tactics Matches in...</td>\n",
       "      <td>\\n\\nBet Gil on AI Final Fantasy Tactics Matche...</td>\n",
       "      <td>Bet Gil on AI Final Fantasy Tactics Matches i...</td>\n",
       "      <td>Herald Publicist</td>\n",
       "      <td>Bet Gil on AI Final Fantasy Tactics Matches in...</td>\n",
       "      <td>['bet', 'gil', 'ai', 'final', 'fantasy', 'tact...</td>\n",
       "      <td>...</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan 2020</td>\n",
       "      <td>1</td>\n",
       "      <td>4458</td>\n",
       "      <td>['hilarious twitch streamnewstechnologycricket...</td>\n",
       "      <td>hilarious twitch streamnewstechnologycricketpo...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[5.5355614e-04 9.9602497e-01 3.4214482e-03]]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                url        date  \\\n",
       "0           0  https://fusionscienceacademy.com/artificial-in...  2020-01-30   \n",
       "1           1  https://health.economictimes.indiatimes.com/ne...  2020-01-10   \n",
       "2           2  https://heraldpublicist.com/bet-gil-on-ai-fina...  2020-01-15   \n",
       "\n",
       "  language                                              title  \\\n",
       "0       en  Artificial Intelligence (AI) in Social Media  ...   \n",
       "1       en  artificial intelligence: Researchers develop A...   \n",
       "2       en  Bet Gil on AI Final Fantasy Tactics Matches in...   \n",
       "\n",
       "                                                text  \\\n",
       "0  \\n\\nArtificial Intelligence (AI) in Social Med...   \n",
       "1  \\n\\nartificial intelligence: Researchers devel...   \n",
       "2  \\n\\nBet Gil on AI Final Fantasy Tactics Matche...   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0   Artificial Intelligence AI in Social MediaMar...   \n",
       "1   artificial intelligence: Researchers develop ...   \n",
       "2   Bet Gil on AI Final Fantasy Tactics Matches i...   \n",
       "\n",
       "                  article_source  \\\n",
       "0  2026 – Fusion Science Academy   \n",
       "1                            NaN   \n",
       "2               Herald Publicist   \n",
       "\n",
       "                                         clean_title  \\\n",
       "0  Artificial Intelligence (AI) in Social Media  ...   \n",
       "1  artificial intelligence: Researchers develop A...   \n",
       "2  Bet Gil on AI Final Fantasy Tactics Matches in...   \n",
       "\n",
       "                                        title_tokens  ... year_pub  month  \\\n",
       "0  ['artificial', 'intelligence', 'ai', 'social',...  ...     2020      1   \n",
       "1  ['artificial', 'intelligence', 'researchers', ...  ...     2020      1   \n",
       "2  ['bet', 'gil', 'ai', 'final', 'fantasy', 'tact...  ...     2020      1   \n",
       "\n",
       "   month-year flag_relevant  num_tokens  \\\n",
       "0    Jan 2020             1       22283   \n",
       "1    Jan 2020             1        8087   \n",
       "2    Jan 2020             1        4458   \n",
       "\n",
       "                               rake_phrases_articles  \\\n",
       "0  ['burkert fluid control systems emerson electr...   \n",
       "1  ['economic times ethealthworldhome news hospit...   \n",
       "2  ['hilarious twitch streamnewstechnologycricket...   \n",
       "\n",
       "                                 rake_phrases_joined final_topic  \\\n",
       "0  burkert fluid control systems emerson electric...           6   \n",
       "1  economic times ethealthworldhome news hospital...           1   \n",
       "2  hilarious twitch streamnewstechnologycricketpo...           1   \n",
       "\n",
       "                                      sent_probs sent_label  \n",
       "0  [[2.1574432e-04 9.9863547e-01 1.1488239e-03]]          1  \n",
       "1  [[1.9508268e-04 8.0524624e-04 9.9899966e-01]]          2  \n",
       "2  [[5.5355614e-04 9.9602497e-01 3.4214482e-03]]          1  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_filt_2020=pd.read_csv('gs://nlp_final_project_kshitijm/00_Data/NLP_FP_Data5_2020_Topics_Sentiments.csv',lineterminator='\\n')\n",
    "df_filt_2020.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0a17382-1b61-4839-813f-5928eee4dd76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f8f7005ad8407eab5465cc39316ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2178), Label(value='0 / 2178'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32667/32667 [00:00<00:00, 786346.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.9 s, sys: 4.79 s, total: 40.7 s\n",
      "Wall time: 8min 14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tqdm.pandas()\n",
    "df_filt_2020['entities_spacy'] = df_filt_2020['cleaned_text'].parallel_apply(lambda x: spacy_ner(x)).progress_apply(lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cc1b1c-0006-49b5-b1b6-f03c0d2755e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filt_2020['ENT_ORG'] = df_filt_2020['entities_spacy'].parallel_apply(lambda x: [tup[0] for tup in x if tup[1] == \"ORG\"])\n",
    "df_filt_2020['ENT_PROD'] = df_filt_2020['entities_spacy'].parallel_apply(lambda x: [tup[0] for tup in x if tup[1] == \"PRODUCT\"])\n",
    "df_filt_2020['ENT_PER'] = df_filt_2020['entities_spacy'].parallel_apply(lambda x: [tup[0] for tup in x if tup[1] == \"PERSON\"])\n",
    "df_filt_2020['ENT_NORP'] = df_filt_2020['entities_spacy'].parallel_apply(lambda x: [tup[0] for tup in x if tup[1] == \"NORP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7b8a135-3b7f-4c73-926b-9f000281f2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.5 s, sys: 525 ms, total: 36 s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "##SAVED AS THE WRONG FILE NAME BY MISTAKE, CORRECT LATER\n",
    "df_filt_2020.to_csv('gs://nlp_final_project_kshitijm/00_Data/NLP_FP_Data5_2021_Topics_Sentiments_NER.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a310ed3-af61-4c6f-af4e-ab0effedd02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organization: AI, Count: 37756\n",
      "Organization: V19, Count: 28787\n",
      "Organization: Google, Count: 20518\n",
      "Organization: Microsoft, Count: 14155\n",
      "Organization: IBM, Count: 13379\n",
      "Organization: Artificial Intelligence, Count: 12495\n",
      "Organization: GR, Count: 11260\n",
      "Organization: Facebook, Count: 9600\n",
      "Organization: Artificial Intelligence AI, Count: 7383\n",
      "Organization: Amazon, Count: 6893\n",
      "Organization: Machine Learning, Count: 6402\n",
      "Organization: Intel, Count: 6191\n",
      "Organization: Apple, Count: 5274\n",
      "Organization: ML, Count: 4460\n",
      "Organization: AsiaPacific, Count: 4086\n",
      "Organization: Healthcare, Count: 3892\n",
      "Organization: Samsung, Count: 3010\n",
      "Organization: Twitter, Count: 2701\n",
      "Organization: Oracle, Count: 2699\n",
      "Organization: IBM Corporation, Count: 2665\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "df_filt_2020_ent_orgs = list(chain.from_iterable(df_filt_2020['ENT_ORG']))\n",
    "\n",
    "counter = Counter(df_filt_2020_ent_orgs)\n",
    "top_20 = counter.most_common(20)\n",
    "for item, count in top_20:\n",
    "    print(f\"Organization: {item}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90b67a28-3a0b-4f81-89e4-07af0bb3d33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products: AI, Count: 70971\n",
      "Products: V19, Count: 2601\n",
      "Products: AIdriven, Count: 1194\n",
      "Products: Twitter YouTube, Count: 1113\n",
      "Products: JavaScript, Count: 984\n",
      "Products: SE, Count: 718\n",
      "Products: Galaxy, Count: 669\n",
      "Products: YouTube, Count: 572\n",
      "Products: TensorFlow, Count: 532\n",
      "Products: Global AI, Count: 459\n",
      "Products: HPC, Count: 443\n",
      "Products: Discovery, Count: 433\n",
      "Products: Javascript Course, Count: 422\n",
      "Products: MasteryData ScienceData, Count: 422\n",
      "Products: Facebook, Count: 390\n",
      "Products: CRM, Count: 369\n",
      "Products: A100, Count: 366\n",
      "Products: FoodProduct, Count: 352\n",
      "Products: Xilinx, Count: 332\n",
      "Products: Windows 10, Count: 326\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "df_filt_2020_ent_prods = list(chain.from_iterable(df_filt_2020['ENT_PROD']))\n",
    "\n",
    "counter = Counter(df_filt_2020_ent_prods)\n",
    "top_20 = counter.most_common(20)\n",
    "for item, count in top_20:\n",
    "    print(f\"Products: {item}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7afaa23e-abb5-4412-b760-0478432d195e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person: Size, Count: 3979\n",
      "Person: Trump, Count: 3283\n",
      "Person: Instagram, Count: 1360\n",
      "Person: Middle EastAfrica, Count: 1277\n",
      "Person: Biden, Count: 1046\n",
      "Person: Richests Richests, Count: 1016\n",
      "Person: Gebru, Count: 886\n",
      "Person: Ai Weiwei, Count: 857\n",
      "Person: Musk, Count: 808\n",
      "Person: Elon Musk, Count: 779\n",
      "Person: Trumps, Count: 776\n",
      "Person: Busco, Count: 774\n",
      "Person: asistencia tcnica para mi solucin de cuidados de salud Busco, Count: 774\n",
      "Person: Donald Trump, Count: 704\n",
      "Person: Pichai, Count: 647\n",
      "Person: BFSI, Count: 613\n",
      "Person: Kyle Wiggers, Count: 587\n",
      "Person: Sundar Pichai, Count: 575\n",
      "Person: Jim Thorpe, Count: 564\n",
      "Person: Mark My ServicesAll, Count: 525\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "df_filt_2020_ent_pers = list(chain.from_iterable(df_filt_2020['ENT_PER']))\n",
    "\n",
    "counter = Counter(df_filt_2020_ent_pers)\n",
    "top_20 = counter.most_common(20)\n",
    "for item, count in top_20:\n",
    "    print(f\"Person: {item}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2e3646e-a3a1-42db-a242-618fa3f40663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORP: Chinese, Count: 4344\n",
      "NORP: American, Count: 1869\n",
      "NORP: European, Count: 1783\n",
      "NORP: British, Count: 1654\n",
      "NORP: Canadian, Count: 1486\n",
      "NORP: French, Count: 1077\n",
      "NORP: Americans, Count: 860\n",
      "NORP: German, Count: 847\n",
      "NORP: Hindu, Count: 742\n",
      "NORP: Tamil, Count: 541\n",
      "NORP: Asian, Count: 513\n",
      "NORP: ian, Count: 446\n",
      "NORP: RemoteMoneyAll, Count: 444\n",
      "NORP: African, Count: 437\n",
      "NORP: Canadians, Count: 434\n",
      "NORP: EUs, Count: 433\n",
      "NORP: Irish, Count: 423\n",
      "NORP: Democratic, Count: 398\n",
      "NORP: Popular, Count: 393\n",
      "NORP: North American, Count: 363\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "df_filt_2020_ent_norp = list(chain.from_iterable(df_filt_2020['ENT_NORP']))\n",
    "\n",
    "counter = Counter(df_filt_2020_ent_norp)\n",
    "top_20 = counter.most_common(20)\n",
    "for item, count in top_20:\n",
    "    print(f\"NORP: {item}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db41014-2002-4108-b886-b3c2ccf275b3",
   "metadata": {},
   "source": [
    "----\n",
    "**2021**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d15fdaf8-2251-41a3-aa35-3ee3c69c84c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a12d78c01ba84423b88d34cd0df8b5b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2858), Label(value='0 / 2858'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_filt_2021=pd.read_csv('gs://nlp_final_project_kshitijm/00_Data/NLP_FP_Data5_2021_Topics_Sentiments.csv',lineterminator='\\n')\n",
    "df_filt_2021['entities_spacy'] = df_filt_2021['cleaned_text'].parallel_apply(lambda x: spacy_ner(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990b239e-afb1-4cb7-913c-60d1e492c0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filt_2021['ENT_ORG'] = df_filt_2021['entities_spacy'].parallel_apply(lambda x: [tup[0] for tup in x if tup[1] == \"ORG\"])\n",
    "df_filt_2021['ENT_PROD'] = df_filt_2021['entities_spacy'].parallel_apply(lambda x: [tup[0] for tup in x if tup[1] == \"PRODUCT\"])\n",
    "df_filt_2021['ENT_PER'] = df_filt_2021['entities_spacy'].parallel_apply(lambda x: [tup[0] for tup in x if tup[1] == \"PERSON\"])\n",
    "df_filt_2021['ENT_NORP'] = df_filt_2021['entities_spacy'].parallel_apply(lambda x: [tup[0] for tup in x if tup[1] == \"NORP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b528fc5-bf26-4e29-8f8c-5074cc6f697e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.5 s, sys: 808 ms, total: 47.3 s\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_filt_2021.to_csv('gs://nlp_final_project_kshitijm/00_Data/NLP_FP_Data6_2021v2_Topics_Sentiments_NER.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50a2dfde-214c-4e1c-b63d-6bc49d33ba1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (2375784512.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/tmp/ipykernel_1328/2375784512.py\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    df_ents=pd.DataFrame({\"ORG\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "def get_top_ents(df):\n",
    "    org_list = list(chain.from_iterable(df['ENT_ORG']))\n",
    "    \n",
    "    \n",
    "    \n",
    "    prod_list = list(chain.from_iterable(df['ENT_PROD']))\n",
    "    per_list = list(chain.from_iterable(df['ENT_PER']))\n",
    "    norp_list = list(chain.from_iterable(df['ENT_NORP']))\n",
    "    \n",
    "counter = Counter(df_filt_2020_ent_norp)\n",
    "top_20 = counter.most_common(20)\n",
    "for item, count in top_20:\n",
    "    print(f\"NORP: {item}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380381f4-e335-4558-bc6d-fbd4e49273d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a07146-d0f8-4b6f-b420-666dabf8729c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d851314a-3e9a-4fb9-bec5-2adc47a868fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27ae4f8d-8d76-4192-82bb-e7f44de89f1a",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "178492df-3228-434e-a39e-5821695d3958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae433fbff7594baa8bf036828457c59f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=3663), Label(value='0 / 3663'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 20s, sys: 11.1 s, total: 1min 31s\n",
      "Wall time: 13min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_filt_2022=pd.read_csv('gs://nlp_final_project_kshitijm/00_Data/NLP_FP_Data5_2022_Topics_Sentiments.csv',lineterminator='\\n')\n",
    "df_filt_2022['entities_spacy'] = df_filt_2022['cleaned_text'].parallel_apply(lambda x: spacy_ner(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47f5a569-0cfe-4852-a44a-2c2ae4c6878a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed2cc1976a247499f50f81854d7c145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=3756), Label(value='0 / 3756'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 22s, sys: 12.6 s, total: 1min 35s\n",
      "Wall time: 14min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_filt_2023=pd.read_csv('gs://nlp_final_project_kshitijm/00_Data/NLP_FP_Data5_2023_Topics_Sentiments.csv',lineterminator='\\n')\n",
    "df_filt_2023['entities_spacy'] = df_filt_2023['cleaned_text'].parallel_apply(lambda x: spacy_ner(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c19368-09be-4a2e-b88e-1bd8872b3588",
   "metadata": {},
   "source": [
    "### Analyzing NERs"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
